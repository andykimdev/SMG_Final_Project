{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretability Analysis: Full Results Generation\n",
        "\n",
        "This notebook runs the complete interpretability pipeline and generates all figures for the results section:\n",
        "\n",
        "- **GaTmCC Performance**: Training curves and test metrics\n",
        "- **PCA Baseline**: Performance comparison\n",
        "- **SHAP Analysis**: Protein importance (100 test samples)\n",
        "- **Attention Analysis**: Attention patterns and correlations\n",
        "- **Comparative Analysis**: Model comparisons and visualizations\n",
        "- **Graph Bias Scale**: Learned parameter analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/leophelan/Code/projects/graph_transformer_proteomics/CleanedProject/Executable_Project_Code\n",
            "Output directory: /Users/leophelan/Code/projects/graph_transformer_proteomics/CleanedProject/Executable_Project_Code/results/plots/Model_Comparison_Plots\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from collections import defaultdict\n",
        "\n",
        "# Determine project root\n",
        "cwd = Path(os.getcwd())\n",
        "if (cwd / \"src\").exists() and (cwd / \"interpretability\").exists():\n",
        "    PROJECT_ROOT = cwd\n",
        "elif (cwd.parent / \"src\").exists() and (cwd.parent / \"interpretability\").exists():\n",
        "    PROJECT_ROOT = cwd.parent\n",
        "else:\n",
        "    PROJECT_ROOT = Path().resolve().parent\n",
        "\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "sys.path.insert(0, str(PROJECT_ROOT / \"interpretability\"))\n",
        "\n",
        "import config\n",
        "from model import GraphTransformerClassifier\n",
        "from graph_prior import load_graph_prior, get_graph_features_as_tensors\n",
        "from utils import load_trained_model, load_data, get_output_dirs, DEFAULT_PATHS, compute_graph_distances\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Setup output directories\n",
        "plots_dir, results_dir = get_output_dirs(PROJECT_ROOT / \"results\")\n",
        "output_dir = plots_dir / \"Model_Comparison_Plots\"\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Run Interpretability Analyses\n",
        "\n",
        "Execute SHAP, attention, and PCA baseline analyses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Running SHAP Analysis (100 test samples)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SHAP Analysis: Protein Importance\n",
            "======================================================================\n",
            "\n",
            "Output directory: /Users/leophelan/Code/projects/graph_transformer_proteomics/CleanedProject/Executable_Project_Code/results/plots/SHAP_Plots\n",
            "Device: cpu (optimized for SHAP compatibility)\n",
            "Using 8 CPU threads\n",
            "\n",
            "Loading model and data...\n",
            "Loaded prior: 198 proteins, 1184 edges\n",
            "Loading data from /Users/leophelan/Code/projects/graph_transformer_proteomics/CleanedProject/Executable_Project_Code/data/processed_datasets/tcga_pancan_rppa_compiled.csv...\n",
            "Loaded 7523 samples\n",
            "Found 198 protein columns in CSV\n",
            "Filtering samples: 7523/7523 have ≤50.0% missing values\n",
            "After filtering: 7523 samples across 32 cancer types\n",
            "Cancer type distribution:\n",
            "CANCER_TYPE_ACRONYM\n",
            "ACC      45\n",
            "BLCA    343\n",
            "BRCA    876\n",
            "CESC    166\n",
            "CHOL     30\n",
            "COAD    346\n",
            "DLBC     33\n",
            "ESCA    125\n",
            "GBM     231\n",
            "HNSC    211\n",
            "KICH     62\n",
            "KIRC    455\n",
            "KIRP    209\n",
            "LGG     428\n",
            "LIHC    179\n",
            "LUAD    360\n",
            "LUSC    317\n",
            "MESO     63\n",
            "OV      414\n",
            "PAAD    122\n",
            "PCPG     79\n",
            "PRAD    350\n",
            "READ    118\n",
            "SARC    218\n",
            "SKCM    329\n",
            "STAD    354\n",
            "TGCT    118\n",
            "THCA    369\n",
            "THYM     90\n",
            "UCEC    423\n",
            "UCS      48\n",
            "UVM      12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data splits:\n",
            "  Train: 6394 samples (85.0%)\n",
            "  Val:   751 samples (10.0%)\n",
            "  Test:  378 samples (5.0%)\n",
            "\n",
            "Handling missing values...\n",
            "  train: 38652 missing values, imputing with train means\n",
            "  val: 4510 missing values, imputing with train means\n",
            "  test: 2291 missing values, imputing with train means\n",
            "\n",
            "Standardizing protein features...\n",
            "  Mean: [-0.72214299  0.3119937   0.21089168  0.78799248  1.543347  ] ... (first 5)\n",
            "  Std:  [0.27372869 0.55241333 0.35098655 0.761766   0.66660206] ... (first 5)\n",
            "Background set: 6394 samples across 32 classes\n",
            "Test set: 378 samples across 32 classes\n",
            "Proteins: 198\n",
            "\n",
            "Computing SHAP values...\n",
            "Stratified sampling: selecting 100 background and 100 test samples...\n",
            "\n",
            "Background set: 100 samples across 25 classes\n",
            "Test set: 100 samples across 25 classes\n",
            "Class distribution in background: {np.int64(1): np.int64(5), np.int64(2): np.int64(12), np.int64(3): np.int64(2), np.int64(5): np.int64(5), np.int64(7): np.int64(1), np.int64(8): np.int64(4), np.int64(9): np.int64(3), np.int64(11): np.int64(7), np.int64(12): np.int64(3), np.int64(13): np.int64(6), np.int64(14): np.int64(2), np.int64(15): np.int64(5), np.int64(16): np.int64(5), np.int64(18): np.int64(6), np.int64(19): np.int64(1), np.int64(20): np.int64(1), np.int64(21): np.int64(5), np.int64(22): np.int64(1), np.int64(23): np.int64(3), np.int64(24): np.int64(5), np.int64(25): np.int64(5), np.int64(26): np.int64(1), np.int64(27): np.int64(5), np.int64(28): np.int64(1), np.int64(29): np.int64(6)}\n",
            "Class distribution in test: {np.int64(1): np.int64(5), np.int64(2): np.int64(12), np.int64(3): np.int64(2), np.int64(5): np.int64(5), np.int64(7): np.int64(1), np.int64(8): np.int64(3), np.int64(9): np.int64(3), np.int64(11): np.int64(7), np.int64(12): np.int64(3), np.int64(13): np.int64(6), np.int64(14): np.int64(3), np.int64(15): np.int64(5), np.int64(16): np.int64(5), np.int64(18): np.int64(6), np.int64(19): np.int64(1), np.int64(20): np.int64(1), np.int64(21): np.int64(5), np.int64(22): np.int64(1), np.int64(23): np.int64(3), np.int64(24): np.int64(5), np.int64(25): np.int64(5), np.int64(26): np.int64(1), np.int64(27): np.int64(5), np.int64(28): np.int64(1), np.int64(29): np.int64(6)}\n",
            "Setting up SHAP explainer...\n",
            "\n",
            "Computing SHAP values...\n",
            "Expected time: ~2.5-3 hours for 100 bg × 100 test samples\n",
            "Will process in batches with live progress updates...\n",
            "\n",
            "\n",
            "→ Starting batch 1/10 (samples 0-9)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leophelan/Code/envs/AI_ML_DL/lib/python3.11/site-packages/shap/explainers/_deep/deep_pytorch.py:255: UserWarning: unrecognized nn.Module: LayerNorm\n",
            "  warnings.warn(f\"unrecognized nn.Module: {module_type}\")\n"
          ]
        }
      ],
      "source": [
        "# Run SHAP analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"Running SHAP Analysis (100 test samples)\")\n",
        "print(\"=\" * 70)\n",
        "try:\n",
        "    from shap_analysis import main as shap_main\n",
        "    shap_main()\n",
        "    print(\"✓ SHAP analysis complete\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ SHAP analysis failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Run attention analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"Running Attention Analysis\")\n",
        "print(\"=\" * 70)\n",
        "try:\n",
        "    from attention_analysis import main as attn_main\n",
        "    attn_main()\n",
        "    print(\"✓ Attention analysis complete\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Attention analysis failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Run PCA baseline\n",
        "print(\"=\" * 70)\n",
        "print(\"Training PCA95 Baseline\")\n",
        "print(\"=\" * 70)\n",
        "try:\n",
        "    from pca_baseline import main as pca_main\n",
        "    pca_main()\n",
        "    print(\"✓ PCA baseline complete\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ PCA baseline failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Pre-computed Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load SHAP results\n",
        "shap_results_path = plots_dir / 'SHAP_Plots' / 'top_proteins.json'\n",
        "with open(shap_results_path, 'r') as f:\n",
        "    shap_data = json.load(f)\n",
        "\n",
        "shap_proteins = [p['protein'] for p in shap_data]\n",
        "shap_importance = np.array([p['importance'] for p in shap_data])\n",
        "shap_dict = {p['protein']: p['importance'] for p in shap_data}\n",
        "\n",
        "print(f\"Loaded SHAP: {len(shap_data)} proteins\")\n",
        "print(f\"Top 5: {shap_proteins[:5]}\")\n",
        "\n",
        "# Load PCA results\n",
        "pca_results_path = plots_dir / 'PCA_Cox_Plots' / 'top_proteins.json'\n",
        "with open(pca_results_path, 'r') as f:\n",
        "    pca_data = json.load(f)\n",
        "\n",
        "pca_proteins = [p['protein'] for p in pca_data]\n",
        "pca_importance = np.array([p['importance'] for p in pca_data])\n",
        "pca_dict = {p['protein']: p['importance'] for p in pca_data}\n",
        "\n",
        "print(f\"\\nLoaded PCA-Logistic: {len(pca_data)} proteins\")\n",
        "print(f\"Top 5: {pca_proteins[:5]}\")\n",
        "\n",
        "# Load PPI network\n",
        "prior_data = np.load(DEFAULT_PATHS['prior'], allow_pickle=True)\n",
        "A = prior_data['A']\n",
        "all_proteins = prior_data['protein_cols'].tolist()\n",
        "\n",
        "print(f\"\\nLoaded PPI network: {A.shape[0]} proteins, {int(A.sum()//2)} edges\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Model and Extract Attention Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model and extract attention\n",
        "device = 'cpu'\n",
        "model, graph_prior, label_info = load_trained_model(device=device)\n",
        "data_splits, protein_names, data_loaders = load_data(return_dataloaders=True)\n",
        "\n",
        "# Extract attention using hooks\n",
        "class AttentionExtractor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.attention_maps = []\n",
        "        self.hooks = []\n",
        "        \n",
        "    def register_hooks(self):\n",
        "        for layer in self.model.transformer:\n",
        "            hook = layer.self_attn.register_forward_hook(self._hook_fn)\n",
        "            self.hooks.append(hook)\n",
        "    \n",
        "    def _hook_fn(self, module, input, output):\n",
        "        attn_weights = output[1]  # (batch, heads, seq_len, seq_len)\n",
        "        self.attention_maps.append(attn_weights.detach().cpu())\n",
        "    \n",
        "    def remove_hooks(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "        self.hooks = []\n",
        "\n",
        "extractor = AttentionExtractor(model)\n",
        "extractor.register_hooks()\n",
        "\n",
        "# Run on test data\n",
        "model.eval()\n",
        "test_loader = data_loaders['test']\n",
        "all_attention = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        _ = model(batch_x)\n",
        "        if extractor.attention_maps:\n",
        "            all_attention.append(extractor.attention_maps)\n",
        "            extractor.attention_maps = []\n",
        "\n",
        "extractor.remove_hooks()\n",
        "\n",
        "# Aggregate attention across layers, heads, and samples\n",
        "if all_attention:\n",
        "    # Flatten list structure: [[layer1_heads], [layer2_heads], ...] per sample\n",
        "    n_layers = len(model.transformer)\n",
        "    n_heads = model.n_heads\n",
        "    n_proteins = A.shape[0]\n",
        "    \n",
        "    attention_matrix = np.zeros((n_proteins, n_proteins))\n",
        "    count = 0\n",
        "    \n",
        "    for sample_attn in all_attention:\n",
        "        for layer_idx, layer_attn in enumerate(sample_attn):\n",
        "            # layer_attn: (batch, heads, seq_len, seq_len)\n",
        "            batch_attn = layer_attn[0]  # (heads, seq_len, seq_len)\n",
        "            for head_idx in range(n_heads):\n",
        "                head_attn = batch_attn[head_idx].numpy()  # (seq_len, seq_len)\n",
        "                # Remove CLS token (first row/col)\n",
        "                protein_attn = head_attn[1:, 1:]  # (n_proteins, n_proteins)\n",
        "                attention_matrix += protein_attn\n",
        "                count += 1\n",
        "    \n",
        "    attention_matrix /= count\n",
        "    \n",
        "    # Compute per-protein attention scores (sum of attention received)\n",
        "    protein_attention = {}\n",
        "    for i, protein in enumerate(all_proteins):\n",
        "        protein_attention[protein] = float(attention_matrix[:, i].sum())\n",
        "    \n",
        "    print(f\"Extracted attention from {len(all_attention)} samples\")\n",
        "    print(f\"Averaged over {n_layers} layers × {n_heads} heads\")\n",
        "else:\n",
        "    attention_matrix = None\n",
        "    protein_attention = {}\n",
        "    print(\"No attention extracted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Performance Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model performance\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "model.eval()\n",
        "test_x, test_y = data_splits['test']\n",
        "test_x_tensor = torch.FloatTensor(test_x).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(test_x_tensor)\n",
        "    preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "test_acc = accuracy_score(test_y, preds)\n",
        "test_f1_macro = f1_score(test_y, preds, average='macro')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"GaTmCC Performance\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"Test F1 (macro): {test_f1_macro*100:.2f}%\")\n",
        "print(f\"Number of classes: {label_info['n_classes']}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load PCA baseline results if available\n",
        "pca_stats_path = plots_dir / 'PCA_Cox_Plots' / 'pca_stats.txt'\n",
        "pca_test_acc = None\n",
        "if pca_stats_path.exists():\n",
        "    with open(pca_stats_path, 'r') as f:\n",
        "        content = f.read()\n",
        "        for line in content.split('\\n'):\n",
        "            if 'Test accuracy' in line.lower():\n",
        "                try:\n",
        "                    pca_test_acc = float(line.split(':')[1].strip().replace('%', '')) / 100\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "if pca_test_acc:\n",
        "    print(f\"\\nPCA95+LogReg Test Accuracy: {pca_test_acc*100:.2f}%\")\n",
        "    print(f\"Difference: {(pca_test_acc - test_acc)*100:.2f}% (PCA advantage)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Result Figures\n",
        "\n",
        "### Figure 3: SHAP vs Attention Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fig 3a: SHAP vs Attention scatter plot (Top 50)\n",
        "top50_shap = shap_proteins[:50]\n",
        "top50_pca_shap = pca_proteins[:50] if len(pca_proteins) >= 50 else pca_proteins\n",
        "\n",
        "common_proteins = [p for p in top50_shap if p in protein_attention and p in all_proteins]\n",
        "shap_vals = [shap_dict[p] for p in common_proteins]\n",
        "attn_vals = [protein_attention[p] for p in common_proteins]\n",
        "\n",
        "# Color: red if in top 50 of either transformer or PCA SHAP\n",
        "overlap_top50 = set(top50_shap[:50]) | set(top50_pca_shap[:50])\n",
        "colors = ['darkred' if p in overlap_top50 else 'steelblue' for p in common_proteins]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Left: Scatter plot\n",
        "ax = axes[0]\n",
        "ax.scatter(shap_vals, attn_vals, c=colors, alpha=0.7, s=100, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "# Label top 10\n",
        "for i, protein in enumerate(common_proteins[:10]):\n",
        "    ax.annotate(protein.split('|')[1] if '|' in protein else protein[:10],\n",
        "                (shap_vals[i], attn_vals[i]),\n",
        "                xytext=(5, 5), textcoords='offset points',\n",
        "                fontsize=8, alpha=0.8,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='none'))\n",
        "\n",
        "if len(shap_vals) > 2:\n",
        "    corr, p_val = pearsonr(shap_vals, attn_vals)\n",
        "    ax.text(0.05, 0.95, f'Pearson r = {corr:.3f}\\np = {p_val:.3f}',\n",
        "           transform=ax.transAxes, fontsize=11,\n",
        "           verticalalignment='top',\n",
        "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "ax.set_xlabel('SHAP Importance', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Attention Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('SHAP vs Attention (Transformer Top 50)\\nRed = Top 50 in Transformer or PCA SHAP', \n",
        "             fontsize=13, fontweight='bold')\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# Right: Correlation distribution\n",
        "ax = axes[1]\n",
        "ax.hist(shap_vals, bins=20, alpha=0.6, label='SHAP', color='steelblue', edgecolor='black')\n",
        "ax_twin = ax.twinx()\n",
        "ax_twin.hist(attn_vals, bins=20, alpha=0.6, label='Attention', color='coral', edgecolor='black')\n",
        "ax.set_xlabel('SHAP Importance', fontsize=12)\n",
        "ax.set_ylabel('Frequency (SHAP)', fontsize=12, color='steelblue')\n",
        "ax_twin.set_ylabel('Frequency (Attention)', fontsize=12, color='coral')\n",
        "ax.set_title('Distribution Comparison', fontsize=13, fontweight='bold')\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'fig3_shap_vs_attention.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Saved: {output_dir / 'fig3_shap_vs_attention.png'}\")\n",
        "print(f\"Correlation: r={corr:.3f}, p={p_val:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4: Attention-based Relational Structure (FASN Example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fig 4: FASN attention connections\n",
        "if attention_matrix is not None:\n",
        "    # Find FASN in proteins\n",
        "    fasn_idx = None\n",
        "    for i, p in enumerate(all_proteins):\n",
        "        if 'FASN' in p:\n",
        "            fasn_idx = i\n",
        "            break\n",
        "    \n",
        "    if fasn_idx is not None:\n",
        "        # Get top proteins FASN attends to\n",
        "        fasn_attention = attention_matrix[fasn_idx, :]\n",
        "        top_indices = np.argsort(fasn_attention)[-20:][::-1]\n",
        "        \n",
        "        # Create submatrix for visualization\n",
        "        selected_indices = [fasn_idx] + [idx for idx in top_indices if idx != fasn_idx][:19]\n",
        "        selected_proteins = [all_proteins[i] for i in selected_indices]\n",
        "        \n",
        "        attention_sub = attention_matrix[np.ix_(selected_indices, selected_indices)]\n",
        "        ppi_sub = A[np.ix_(selected_indices, selected_indices)]\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "        \n",
        "        # Left: Attention heatmap\n",
        "        ax = axes[0]\n",
        "        sns.heatmap(attention_sub, cmap='RdYlBu_r', square=True,\n",
        "                   xticklabels=[p.split('|')[1] if '|' in p else p[:15] for p in selected_proteins],\n",
        "                   yticklabels=[p.split('|')[1] if '|' in p else p[:15] for p in selected_proteins],\n",
        "                   cbar_kws={'label': 'Attention Weight'},\n",
        "                   ax=ax, fmt='.3f')\n",
        "        ax.set_title('FASN Attention Pattern\\n(Top 20 connected proteins)', \n",
        "                    fontsize=14, fontweight='bold', pad=15)\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "        plt.setp(ax.get_yticklabels(), rotation=0)\n",
        "        \n",
        "        # Right: PPI network overlay\n",
        "        ax = axes[1]\n",
        "        sns.heatmap(ppi_sub, cmap='Blues', square=True,\n",
        "                   xticklabels=[p.split('|')[1] if '|' in p else p[:15] for p in selected_proteins],\n",
        "                   yticklabels=[p.split('|')[1] if '|' in p else p[:15] for p in selected_proteins],\n",
        "                   cbar_kws={'label': 'PPI Edge'},\n",
        "                   ax=ax, fmt='d')\n",
        "        ax.set_title('PPI Network Structure\\n(Same proteins)', \n",
        "                    fontsize=14, fontweight='bold', pad=15)\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "        plt.setp(ax.get_yticklabels(), rotation=0)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / 'fig4_fasn_attention.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # Print connections\n",
        "        print(\"FASN top attention connections:\")\n",
        "        for i, idx in enumerate(top_indices[:10], 1):\n",
        "            protein = all_proteins[idx]\n",
        "            attn_val = fasn_attention[idx]\n",
        "            ppi_edge = int(A[fasn_idx, idx])\n",
        "            print(f\"  {i:2d}. {protein:30s} | Attention: {attn_val:.4f} | PPI: {ppi_edge}\")\n",
        "        \n",
        "        print(f\"\\nSaved: {output_dir / 'fig4_fasn_attention.png'}\")\n",
        "    else:\n",
        "        print(\"FASN not found in protein list\")\n",
        "else:\n",
        "    print(\"Attention matrix not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 5: Graph Bias Scale Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract graph_bias_scale from model\n",
        "graph_bias_scales = []\n",
        "for layer in model.transformer:\n",
        "    if hasattr(layer.self_attn, 'graph_bias_scale'):\n",
        "        bias_scale = layer.self_attn.graph_bias_scale.detach().cpu().numpy()\n",
        "        graph_bias_scales.append(bias_scale)\n",
        "\n",
        "if graph_bias_scales:\n",
        "    graph_bias_scales = np.array(graph_bias_scales)  # (n_layers, n_heads)\n",
        "    n_layers, n_heads = graph_bias_scales.shape\n",
        "    \n",
        "    # Statistics\n",
        "    mean_val = graph_bias_scales.mean()\n",
        "    std_val = graph_bias_scales.std()\n",
        "    var_val = graph_bias_scales.var()\n",
        "    min_val = graph_bias_scales.min()\n",
        "    max_val = graph_bias_scales.max()\n",
        "    range_val = max_val - min_val\n",
        "    cv = std_val / mean_val if mean_val != 0 else 0\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(\"Graph Bias Scale Statistics\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Mean: {mean_val:.6f}\")\n",
        "    print(f\"Std: {std_val:.6f}\")\n",
        "    print(f\"Variance: {var_val:.6f}\")\n",
        "    print(f\"Min: {min_val:.6f}\")\n",
        "    print(f\"Max: {max_val:.6f}\")\n",
        "    print(f\"Range: {range_val:.6f}\")\n",
        "    print(f\"Coefficient of Variation: {cv:.6f}\")\n",
        "    print(f\"Shape: {n_layers} layers × {n_heads} heads\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Fig 5: Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    \n",
        "    # Top left: Bar chart per head (mean across layers)\n",
        "    ax = axes[0, 0]\n",
        "    head_means = graph_bias_scales.mean(axis=0)\n",
        "    ax.bar(range(n_heads), head_means, color='steelblue', edgecolor='black', alpha=0.8)\n",
        "    ax.axhline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Overall mean: {mean_val:.4f}')\n",
        "    ax.set_xlabel('Attention Head', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Mean Graph Bias Scale', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Graph Bias Scale by Head\\n(Mean across layers)', fontsize=13, fontweight='bold')\n",
        "    ax.set_xticks(range(n_heads))\n",
        "    ax.set_xticklabels([f'H{i+1}' for i in range(n_heads)])\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "    \n",
        "    # Top right: Histogram\n",
        "    ax = axes[0, 1]\n",
        "    ax.hist(graph_bias_scales.flatten(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.4f}')\n",
        "    ax.set_xlabel('Graph Bias Scale', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Distribution of Graph Bias Scale\\n(All layers × heads)', fontsize=13, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "    \n",
        "    # Bottom left: Heatmap (layers × heads)\n",
        "    ax = axes[1, 0]\n",
        "    sns.heatmap(graph_bias_scales, cmap='RdYlBu_r', annot=True, fmt='.4f',\n",
        "               xticklabels=[f'H{i+1}' for i in range(n_heads)],\n",
        "               yticklabels=[f'L{i+1}' for i in range(n_layers)],\n",
        "               cbar_kws={'label': 'Graph Bias Scale'},\n",
        "               ax=ax, square=True)\n",
        "    ax.set_xlabel('Attention Head', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Layer', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Graph Bias Scale Heatmap\\n(Layers × Heads)', fontsize=13, fontweight='bold')\n",
        "    \n",
        "    # Bottom right: Box plot by layer\n",
        "    ax = axes[1, 1]\n",
        "    data_for_box = [graph_bias_scales[i, :] for i in range(n_layers)]\n",
        "    bp = ax.boxplot(data_for_box, labels=[f'L{i+1}' for i in range(n_layers)],\n",
        "                   patch_artist=True)\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('steelblue')\n",
        "        patch.set_alpha(0.7)\n",
        "    ax.axhline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.4f}')\n",
        "    ax.set_xlabel('Layer', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Graph Bias Scale', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Graph Bias Scale Distribution by Layer', fontsize=13, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir / 'fig5_graph_bias_scale.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nSaved: {output_dir / 'fig5_graph_bias_scale.png'}\")\n",
        "else:\n",
        "    print(\"Graph bias scale not found in model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fig 2: Model comparison bar chart\n",
        "if pca_test_acc:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    \n",
        "    # Left: Accuracy comparison\n",
        "    ax = axes[0]\n",
        "    models = ['PCA95+LogReg', 'GaTmCC']\n",
        "    accuracies = [pca_test_acc * 100, test_acc * 100]\n",
        "    colors = ['steelblue', 'darkgreen']\n",
        "    \n",
        "    bars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5, alpha=0.8)\n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "               f'{acc:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "    \n",
        "    ax.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Model Comparison: Accuracy', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylim(0, max(accuracies) + 5)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Right: F1 comparison\n",
        "    ax = axes[1]\n",
        "    # Try to get PCA F1 from stats file\n",
        "    pca_f1 = None\n",
        "    if pca_stats_path.exists():\n",
        "        with open(pca_stats_path, 'r') as f:\n",
        "            content = f.read()\n",
        "            for line in content.split('\\n'):\n",
        "                if 'f1' in line.lower() and 'macro' in line.lower():\n",
        "                    try:\n",
        "                        pca_f1 = float(line.split(':')[1].strip().replace('%', '')) / 100\n",
        "                    except:\n",
        "                        pass\n",
        "    \n",
        "    if pca_f1:\n",
        "        f1_scores = [pca_f1 * 100, test_f1_macro * 100]\n",
        "        bars = ax.bar(models, f1_scores, color=colors, edgecolor='black', linewidth=1.5, alpha=0.8)\n",
        "        for bar, f1 in zip(bars, f1_scores):\n",
        "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                   f'{f1:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "        ax.set_ylabel('Test F1 (macro) (%)', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Model Comparison: F1 Score', fontsize=13, fontweight='bold')\n",
        "        ax.set_ylim(0, max(f1_scores) + 5)\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, 'F1 scores not available', ha='center', va='center',\n",
        "               transform=ax.transAxes, fontsize=12)\n",
        "        ax.set_title('Model Comparison: F1 Score', fontsize=13, fontweight='bold')\n",
        "    \n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir / 'fig2_model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Saved: {output_dir / 'fig2_model_comparison.png'}\")\n",
        "else:\n",
        "    print(\"PCA baseline results not available for comparison\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 1: Training Curves (if available)\n",
        "\n",
        "Note: Training logs may not be available if model was pretrained. This cell checks for log files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for training logs\n",
        "log_paths = [\n",
        "    PROJECT_ROOT / \"results\" / \"classifiers\" / \"cancer_type_classifiers\" / \"transformer\" / \"training.log\",\n",
        "    PROJECT_ROOT / \"results\" / \"classifiers\" / \"cancer_type_classifiers\" / \"transformer\" / \"logs\" / \"training.log\",\n",
        "    PROJECT_ROOT.parent / \"CleanedProject\" / \"Results\" / \"classifiers\" / \"cancer_type_classifiers\" / \"transformer\" / \"training.log\",\n",
        "]\n",
        "\n",
        "training_log = None\n",
        "for path in log_paths:\n",
        "    if path.exists():\n",
        "        training_log = path\n",
        "        break\n",
        "\n",
        "if training_log:\n",
        "    print(f\"Found training log: {training_log}\")\n",
        "    # Parse log file (basic parsing - adjust based on actual log format)\n",
        "    epochs = []\n",
        "    train_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    with open(training_log, 'r') as f:\n",
        "        for line in f:\n",
        "            if 'epoch' in line.lower() and 'loss' in line.lower():\n",
        "                # Try to extract epoch and loss (adjust regex based on actual format)\n",
        "                import re\n",
        "                epoch_match = re.search(r'epoch[:\\s]+(\\d+)', line, re.I)\n",
        "                loss_match = re.search(r'loss[:\\s]+([\\d.]+)', line, re.I)\n",
        "                if epoch_match and loss_match:\n",
        "                    epochs.append(int(epoch_match.group(1)))\n",
        "                    train_losses.append(float(loss_match.group(1)))\n",
        "            if 'val' in line.lower() and 'acc' in line.lower():\n",
        "                acc_match = re.search(r'acc[:\\s]+([\\d.]+)', line, re.I)\n",
        "                if acc_match:\n",
        "                    val_accs.append(float(acc_match.group(1)))\n",
        "    \n",
        "    if epochs and train_losses:\n",
        "        # Ensure same length\n",
        "        min_len = min(len(epochs), len(train_losses), len(val_accs) if val_accs else len(epochs))\n",
        "        epochs = epochs[:min_len]\n",
        "        train_losses = train_losses[:min_len]\n",
        "        if val_accs:\n",
        "            val_accs = val_accs[:min_len]\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        \n",
        "        # Left: Training loss\n",
        "        ax = axes[0]\n",
        "        ax.plot(epochs, train_losses, 'b-', linewidth=2, label='Training Loss', marker='o', markersize=4)\n",
        "        ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Training Loss Over Time', fontsize=13, fontweight='bold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Right: Validation accuracy\n",
        "        ax = axes[1]\n",
        "        if val_accs:\n",
        "            ax.plot(epochs, [a*100 for a in val_accs], 'g-', linewidth=2, label='Validation Accuracy', marker='s', markersize=4)\n",
        "            ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, 'Validation accuracy\\nnot found in log', \n",
        "                   ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
        "        ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Validation Accuracy Over Time', fontsize=13, fontweight='bold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / 'fig1_training_curves.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"Saved: {output_dir / 'fig1_training_curves.png'}\")\n",
        "    else:\n",
        "        print(\"Could not parse training log\")\n",
        "else:\n",
        "    print(\"Training log not found. If you have training logs, place them in:\")\n",
        "    print(\"  results/classifiers/cancer_type_classifiers/transformer/training.log\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All interpretability analyses complete. Generated figures:\n",
        "- **Fig 1**: Training curves (if available)\n",
        "- **Fig 2**: Model comparison (PCA vs Transformer)\n",
        "- **Fig 3**: SHAP vs Attention correlation\n",
        "- **Fig 4**: Attention relational structure (FASN example)\n",
        "- **Fig 5**: Graph bias scale analysis\n",
        "\n",
        "All figures saved to: `results/plots/Model_Comparison_Plots/`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "AI_ML_DL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
